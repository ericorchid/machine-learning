{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline of multi-classification\n",
    "![](https://watertap.oss-ap-southeast-2.aliyuncs.com/img/20210313214431.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "$$ softmax(\\vec{x_i}) = \\frac{e^{x_i}}{\\sum{e^{x_j}}}$$\n",
    "\n",
    "假设一个向量，描述同事最近的各种情况，预测他的心情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "person1 = [8.5, 34, 173, 54] # 工作8.5个小时， 34岁， 173cm， 54kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "心情 = ['开心', '难过', '平静', '生气', '惊喜']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.48646436,  1.33464191, -0.16997196,  0.31751428, -1.52605198],\n",
       "       [ 3.15491439,  0.79582594, -0.40743345, -0.25555758, -0.25794931],\n",
       "       [ 0.29781294, -0.8930184 , -1.37124732, -1.35311116,  1.56214044],\n",
       "       [ 0.03991902,  0.23419123,  0.22428729, -0.51159647,  1.56125781]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.random.randn(4,5)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0953484180385229"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = np.random.random()\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y_ = wx + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 148.40475534, -103.34796987, -240.31642269, -267.60917886,\n",
       "        332.91184811])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ = np.dot(person1, weights) + bias\n",
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x - np.max(x)\n",
    "    return np.exp(x)/np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.40606868e-081, 3.42585025e-190, 1.12234175e-249, 1.57409783e-261,\n",
       "       1.00000000e+000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weights 初始是 0-1 的小数，softmax之前的wx+b，如果x不做归一化，就会参差不齐。这样得到的softmax会一个接近1，其他接近0，并非想要的效果\n",
    "\n",
    "### 对 x 进行归一化, 这里因为只有一个person的数据，无法归一化，故先随意定值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "person1_norm = [-1.48646436,  1.33464191, -0.16997196,  0.31751428]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.47766069, -0.6002594 ,  0.10851593, -0.65015133,  2.24970192])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ = np.dot(person1_norm, weights) + bias\n",
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.82374484e-01, 8.28658199e-04, 1.68342065e-03, 7.88329256e-04,\n",
       "       1.43251081e-02])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = softmax(y_)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Entropy\n",
    "### 衡量这一组weights和bias的好坏程度，Loss_func\n",
    "$$cross-entropy(label, y_softmax) = - \\sum_{i\\in{N}}{label_i * log(ysoftmax(i))}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = [0, 1, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.48646436,  1.33464191, -0.16997196,  0.31751428, -1.52605198],\n",
       "       [ 3.15491439,  0.79582594, -0.40743345, -0.25555758, -0.25794931],\n",
       "       [ 0.29781294, -0.8930184 , -1.37124732, -1.35311116,  1.56214044],\n",
       "       [ 0.03991902,  0.23419123,  0.22428729, -0.51159647,  1.56125781]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0953484180385229"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(label, y_softmax):\n",
    "    return -sum(label[i] * np.log(y_softmax[i]) for i in range(len(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0957027933760255"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(y_label, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.0957027930371055"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(8.28658199e-04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradicent 交叉熵损失函数的偏导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01762551622212638\n",
      "[-1.48646436, 1.33464191, -0.16997196, 0.31751428]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.0261997 , -0.02352375,  0.00299584, -0.00559635])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 偏导\n",
    "# gradient_loss = (y_predict - y_label) * person1_norm\n",
    "print(max(y_predict) - 1)\n",
    "print(person1_norm)\n",
    "gradient_loss = np.dot((max(y_predict) - 1) , person1_norm)\n",
    "gradient_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.48646436  3.15491439  0.29781294  0.03991902]\n",
      " [ 1.33464191  0.79582594 -0.8930184   0.23419123]\n",
      " [-0.16997196 -0.40743345 -1.37124732  0.22428729]\n",
      " [ 0.31751428 -0.25555758 -1.35311116 -0.51159647]\n",
      " [-1.52605198 -0.25794931  1.56214044  1.56125781]]\n"
     ]
    }
   ],
   "source": [
    "print(weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.51266406  3.17843814  0.29481709  0.04551537]\n",
      " [ 1.3084422   0.8193497  -0.89601424  0.23978759]\n",
      " [-0.19617166 -0.38390969 -1.37424316  0.22988364]\n",
      " [ 0.29131458 -0.23203383 -1.35610701 -0.50600012]\n",
      " [-1.55225168 -0.23442556  1.5591446   1.56685416]]\n"
     ]
    }
   ],
   "source": [
    "print(weights.T-gradient_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.51266406,  1.3084422 , -0.19617166,  0.29131458, -1.55225168],\n",
       "       [ 3.17843814,  0.8193497 , -0.38390969, -0.23203383, -0.23442556],\n",
       "       [ 0.29481709, -0.89601424, -1.37424316, -1.35610701,  1.5591446 ],\n",
       "       [ 0.04551537,  0.23978759,  0.22988364, -0.50600012,  1.56685416]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_adj = (weights.T-gradient_loss).T\n",
    "weights_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11297393426064928"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_adj = bias - (max(y_predict) - 1)\n",
    "bias_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.56791305, -0.51000705,  0.19876829, -0.55989897,  2.33995428])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_adj = np.dot(person1_norm, weights_adj) + bias_adj\n",
    "y_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.82374484e-01, 8.28658199e-04, 1.68342065e-03, 7.88329256e-04,\n",
       "       1.43251081e-02])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(y_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迭代n次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.09570279337647\n",
      "7.095702793376473\n",
      "7.095702793376697\n",
      "7.095702793376693\n",
      "7.09570279337669\n",
      "7.095702793376697\n",
      "7.09570279337647\n",
      "7.095702793367394\n",
      "7.095702793367617\n",
      "7.0957027933747066\n"
     ]
    }
   ],
   "source": [
    "_n_ = 10000\n",
    "\n",
    "for i in range(_n_):\n",
    "    y_pred = softmax(np.dot(person1_norm, weights) + bias)\n",
    "    loss = cross_entropy(y_label, y_pred)\n",
    "    if i%1000 == 0:\n",
    "        print(loss)\n",
    "    grandient_loss = np.dot((max(y_predict) - 1) , person1_norm)\n",
    "    weights = (weights.T - grandient_loss).T\n",
    "    bias = bias - (max(y_predict) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
